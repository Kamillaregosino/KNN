# Algoritmo de Aprendizado Supervisionado KNN

## √â um algoritmo de classifica√ß√£o e regress√£o baseado em dist√¢ncias. Ele √© √∫til especialmente para dados limpos, mas ele n√£o constr√≥i um modelo durante o treino, apenas armazena os dados.

---

# Classifica√ß√£o

1. Fornece um ponto para classificar;
2. O KNN mede a dist√¢ncia entre esse ponto e todos os pontos do conjunto de treino;
3. Seleciona os K vizinhos mais pr√≥ximos;
4. A classe mais comum entre esses vizinhos define a classe predita (por vota√ß√£o).

---

# Regress√£o

**Diferente da classifica√ß√£o, ao inv√©s de votar, ele tira a m√©dia dos valores dos K vizinhos mais pr√≥ximos.**

---

# Passos T√©cnicos

1. Escolher K ( n√∫mero de vizinhos);
2. Calcular a distancia;
3. Selecionar os K vizinhos mais pr√≥ximos;
4. Decidir a sa√≠da ( voto para classifica√ß√£o ou m√©dia para regress√£o).

---

# Tipos de Dist√¢ncias

1. Euclidiana: dist√¢ncia entre 2 pontos;
2. Manhattan: somat√≥ria da diferen√ßa absoluta das coordenadas;
3. Minkowski: Ela define uma m√©trica de dist√¢ncia entre dois pontos em um espa√ßo vetorial, controlada por um par√¢metro ùëù.

---

# Dicas

1. **Escolha do K:** N√∫mero √≠mpar para classifica√ß√£o bin√°ria e usar valida√ß√£o cruzada para escolher o melhor K;
2. **Normaliza√ß√£o:** Usar StandardScaler ou MinMaxScaler para noraliza√ß√£o;
3. **Dados ruidosos:** Outliers afetam o desempenho, ent√£o deve-se ponderar vizinhos mais pr√≥ximos;
4. **Desempenho:** Custo alto com dados grandes.

---

# Funcionamento 

1. Calcular a distancia entre o ponto de teste e todos os pontos de treino;
2. Ordenar os pontos pela menor distancia;
3. Pegar os k vizinhos mais pr√≥ximos;
4. Retornar a classe mais comum entre os vizinhos.

